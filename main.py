from langchain_ollama import OllamaLLM
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_text_splitters import CharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

def main():
    # 1. Khá»Ÿi táº¡o LLM Ollama (Äáº£m báº£o báº¡n Ä‘Ã£ cháº¡y 'ollama pull llama3')
    print("--- Äang káº¿t ná»‘i vá»›i Ollama (Model: llama3)... ---")
    llm = OllamaLLM(model="llama3")

    # 2. Dá»¯ liá»‡u máº«u Ä‘á»ƒ mÃ¡y há»c
    print("--- Äang chuáº©n bá»‹ dá»¯ liá»‡u máº«u... ---")
    data = """
    Äá»“ Ã¡n nÃ y lÃ  vá» há»‡ thá»‘ng RAG cháº¡y trÃªn Ollama.
    Thá»±c hiá»‡n Ä‘á»“ Ã¡n nÃ y cÃ³ lÃ  má»™t nhÃ³m cÃ³ 3 sinh viÃªn nÄƒm 4 gá»“m: LÆ°Æ¡ng Cáº©m ÄÃ o, Huá»³nh Táº¥n DÆ°Æ¡ng vÃ  Há»“ Há»¯u Äáº¡i.
    Giáº£ng viÃªn hÆ°á»›ng dáº«n lÃ  Tiáº¿n sÄ© Trá»‹nh Táº¥n Äáº¡t.
    Thá»i gian thá»±c hiá»‡n Ä‘á»“ Ã¡n lÃ  7 tuáº§n.
    Há»‡ thá»‘ng sá»­ dá»¥ng LangChain Ä‘á»ƒ káº¿t ná»‘i vÃ  ChromaDB Ä‘á»ƒ lÆ°u trá»¯ vector.
    Má»¥c tiÃªu lÃ  táº¡o ra má»™t Chatbot cÃ³ thá»ƒ tráº£ lá»i dá»±a trÃªn tÃ i liá»‡u cÃ¡ nhÃ¢n.
    """

    # 3. Chia nhá» vÄƒn báº£n (Chunking)
    text_splitter = CharacterTextSplitter(chunk_size=150, chunk_overlap=20)
    texts = text_splitter.split_text(data)

    # 4. Táº¡o Embedding Model (Táº£i model tÃ­ hon tá»« HuggingFace vá» mÃ¡y)
    print("--- Äang khá»Ÿi táº¡o Embedding (Láº§n Ä‘áº§u sáº½ táº£i model khoáº£ng 80MB)... ---")
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    # 5. LÆ°u vÃ o Vector Database (Chá»‰ lÆ°u táº¡m thá»i trong bá»™ nhá»› Ä‘á»ƒ test)
    print("--- Äang Ä‘Æ°a dá»¯ liá»‡u vÃ o Vector DB... ---")
    vectorstore = Chroma.from_texts(texts, embeddings)

    # 6. Táº¡o quy trÃ¬nh RAG (LCEL - cÃ¡ch má»›i)
    template = """
        Báº¡n lÃ  trá»£ lÃ½ AI chá»‰ tráº£ lá»i dá»±a trÃªn ngá»¯ cáº£nh Ä‘Æ°á»£c cung cáº¥p.

        QUAN TRá»ŒNG: 
        - CHá»ˆ sá»­ dá»¥ng thÃ´ng tin tá»« ngá»¯ cáº£nh bÃªn dÆ°á»›i Ä‘á»ƒ tráº£ lá»i
        - KHÃ”NG sá»­ dá»¥ng kiáº¿n thá»©c bÃªn ngoÃ i
        - Náº¿u ngá»¯ cáº£nh KHÃ”NG chá»©a thÃ´ng tin cáº§n thiáº¿t, hÃ£y tráº£ lá»i: "TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin nÃ y trong tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p."
        - Chá»‰ tráº£ lá»i báº±ng tiáº¿ng Viá»‡t.

        Ngá»¯ cáº£nh:
        {context}

        CÃ¢u há»i: {question}

        Tráº£ lá»i:"""
    
    prompt = ChatPromptTemplate.from_template(template)
    retriever = vectorstore.as_retriever()
    
    # Táº¡o chain vá»›i LCEL
    qa_chain = (
        {"context": retriever, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )

    # 7. VÃ²ng láº·p há»i Ä‘Ã¡p liÃªn tá»¥c
    print("\n" + "="*60)
    print("ğŸ¤– Chatbot RAG Ä‘Ã£ sáºµn sÃ ng!")
    print("ğŸ’¡ GÃµ 'exit', 'quit', hoáº·c 'thoÃ¡t' Ä‘á»ƒ káº¿t thÃºc")
    print("="*60 + "\n")
    
    while True:
        query = input("ğŸ™‹ Báº¡n: ").strip()
        
        # Kiá»ƒm tra lá»‡nh thoÃ¡t
        if query.lower() in ['exit', 'quit', 'thoÃ¡t', 'thoat']:
            print("\nğŸ‘‹ Táº¡m biá»‡t! Háº¹n gáº·p láº¡i.")
            break
        
        # Bá» qua náº¿u cÃ¢u há»i trá»‘ng
        if not query:
            continue
        
        try:
            response = qa_chain.invoke(query)
            print(f"ğŸ¤– AI: {response}\n")
        except Exception as e:
            print(f"âŒ CÃ³ lá»—i xáº£y ra: {e}\n")

if __name__ == "__main__":
    main()